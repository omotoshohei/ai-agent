import traceback
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# dotenvã‚’åˆ©ç”¨ã™ã‚‹å ´åˆ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenvãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’æ‰‹å‹•ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚", ImportWarning)

PROMPT = """
## ã‚¿ã‚¹ã‚¯: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¾çŠ¶ã¨é¡˜æœ›ã«åŸºã¥ã„ãŸè©³ç´°ã§å€‹åˆ¥åŒ–ã•ã‚ŒãŸã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹ã€‚
## ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±:
- ç¾åœ¨ã®ã‚­ãƒ£ãƒªã‚¢ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {input_status}
- ã‚­ãƒ£ãƒªã‚¢ç›®æ¨™: {input_goal}
- ã‚¹ã‚­ãƒ«ã¨çµŒé¨“: {input_skill}
- èˆˆå‘³: {input_interest}
- å¥½ã¾ã—ã„è·å ´ç’°å¢ƒ: {input_environment}
- å ´æ‰€: {input_location}
- èª²é¡Œ: {input_challenges}

## ç›®çš„: çŸ­æœŸçš„ãŠã‚ˆã³é•·æœŸçš„ãªç›®æ¨™ã‚’é”æˆã™ã‚‹ã®ã«å½¹ç«‹ã¤è¡Œå‹•å¯èƒ½ã§ã‚µãƒãƒ¼ãƒˆçš„ãªã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹ã€‚èª²é¡Œã®å…‹æœã€ã‚¹ã‚­ãƒ«ã®æ´»ç”¨ã€èˆˆå‘³ã‚„å¥½ã¾ã—ã„è·å ´ç’°å¢ƒã¨ã®èª¿å’Œã«ç„¦ç‚¹ã‚’å½“ã¦ãŸæˆ¦ç•¥ã‚’å«ã‚ã‚‹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç‹¬è‡ªã®çŠ¶æ³ã«åˆã‚ã›ãŸå…·ä½“çš„ãªãƒ’ãƒ³ãƒˆã¨æ¨å¥¨äº‹é …ã‚’æä¾›ã™ã‚‹ã€‚
## è¿½åŠ : ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãŒæ˜ç¢ºã§å®Ÿç”¨çš„ã§ã‚ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã«ã¤ã„ã¦æƒ…å ±ã«åŸºã¥ã„ãŸæ±ºå®šã‚’ã™ã‚‹ã®ã«å½¹ç«‹ã¤ã‚ˆã†ã«ã™ã‚‹ã€‚
"""

def init_page():
    st.set_page_config(page_title="ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãƒ„ãƒ¼ãƒ«", page_icon="ğŸ§˜")
    st.header("ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãƒ„ãƒ¼ãƒ«ğŸ§˜")


def select_model(temperature=0):
    models = ("GPT-4o","GPT-4o-mini", "Claude 3.5 Sonnet", "Gemini 1.5 Pro")
    model_choice = st.radio("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ:", models)
    if model_choice == "GPT-4o":
        return ChatOpenAI(temperature=temperature, model_name="gpt-4o")
    elif model_choice == "GPT-4o-mini":
        return ChatOpenAI(temperature=temperature, model_name="gpt-4o-mini")
    elif model_choice == "Claude 3.5 Sonnet":
        return ChatAnthropic(temperature=temperature, model_name="claude-3-5-sonnet-20240620")
    elif model_choice == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(temperature=temperature, model="gemini-1.5-pro-latest")

def init_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_messages([
        ("user", PROMPT),
    ])
    output_parser = StrOutputParser()
    chain = prompt | llm | output_parser
    return chain

def main():
    init_page()
    chain = init_chain()
    if chain:
        input_status = st.selectbox("ç¾åœ¨ã®ã‚­ãƒ£ãƒªã‚¢ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",("å­¦ç”Ÿ", "åˆç´šè·å“¡", "ä¸Šç´šè·å“¡", "ã‚­ãƒ£ãƒªã‚¢ãƒã‚§ãƒ³ã‚¸ãƒ£ãƒ¼", "ç„¡è·ãƒ»æ±‚è·ä¸­", "èµ·æ¥­å®¶"),key="input_status")
        input_goal = st.text_input("ã‚­ãƒ£ãƒªã‚¢ç›®æ¨™ï¼ˆä¾‹ï¼šãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®å°‚é–€å®¶ã¨ã—ã¦èªçŸ¥ã•ã‚Œã‚‹ã“ã¨ï¼‰", key="input_goal")
        input_skill = st.text_input("ã‚¹ã‚­ãƒ«ã¨çµŒé¨“ï¼ˆä¾‹ï¼šSEOã¨ãƒ‡ã‚¸ã‚¿ãƒ«ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ï¼‰", key="input_skill")
        input_interest = st.text_input("èˆˆå‘³ï¼ˆä¾‹ï¼šãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã¨Pythonï¼‰", key="input_interest")
        input_environment = st.selectbox("å¥½ã¾ã—ã„è·å ´ç’°å¢ƒ",("ä¼æ¥­ã‚ªãƒ•ã‚£ã‚¹", "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—", "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯", "ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ãƒ»å¥‘ç´„", "æ”¿åºœãƒ»å…¬å…±ã‚»ã‚¯ã‚¿ãƒ¼"),key="input_environment")
        input_location = st.text_input("å ´æ‰€ï¼ˆä¾‹ï¼šæ±äº¬ï¼‰", key="input_location")
        input_challenges = st.text_input("èª²é¡Œï¼ˆä¾‹ï¼šåˆ†é‡å†…ã®ä»•äº‹ã«ãŠã‘ã‚‹ç«¶äº‰ãŒæ¿€ã—ãã€é›‡ç”¨è€…ã«ç›®ç«‹ã¤ã“ã¨ãŒå›°é›£ï¼‰", key="input_challenges")
        if st.button("æå‡º"):
            result = chain.stream({"input_status": input_status, "input_goal": input_goal, "input_skill": input_skill, "input_interest": input_interest, "input_environment": input_environment, "input_location": input_location, "input_challenges": input_challenges})
            st.write(result)              
                
if __name__ == '__main__':
    main()

# Style adjustments (optional, remove if not needed)
st.markdown(
"""
<style>
/* Custom style adjustments */
.st-emotion-cache-iiif1v { display: none !important; }
</style>
""",
    unsafe_allow_html=True,
)


