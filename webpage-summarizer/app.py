import traceback
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

###### dotenv ã‚’åˆ©ç”¨ã—ãªã„å ´åˆã¯æ¶ˆã—ã¦ãã ã•ã„ ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


SUMMARIZE_PROMPT = """ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã¤ã„ã¦ã€å†…å®¹ã‚’300æ–‡å­—ç¨‹åº¦ã§ã‚ã‹ã‚Šã‚„ã™ãç®‡æ¡æ›¸ãã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

========

{content}

========

æ—¥æœ¬èªã§æ›¸ã„ã¦ã­ï¼
"""


def init_page():
    st.set_page_config(
        page_title="Webpage Summarizer",
        page_icon="ğŸŒ"
    )
    st.header("Webpage Summarizer ğŸŒğŸ“")


def select_model(temperature=0):
    models = ("GPT-4o","GPT-4o-mini", "Claude 3.5 Sonnet", "Gemini 1.5 Pro")
    model_choice = st.radio("Choose a model:", models)
    if model_choice == "GPT-4o":
        return ChatOpenAI(temperature=temperature, model_name="gpt-4o")
    elif model_choice == "GPT-4o-mini":
        return ChatOpenAI(temperature=temperature, model_name="gpt-4o-mini")
    elif model_choice == "Claude 3.5 Sonnet":
        return ChatAnthropic(temperature=temperature, model_name="claude-3-5-sonnet-20240620")
    elif model_choice == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(temperature=temperature, model="gemini-1.5-pro-latest")


def init_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_messages([
        ("user", SUMMARIZE_PROMPT),
    ])
    output_parser = StrOutputParser()
    chain = prompt | llm | output_parser
    return chain


def validate_url(url):
    """ URLãŒæœ‰åŠ¹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•° """
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False


def get_content(url):
    try:
        with st.spinner("Fetching Website ..."):
            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')
            # ãªã‚‹ã¹ãæœ¬æ–‡ã®å¯èƒ½æ€§ãŒé«˜ã„è¦ç´ ã‚’å–å¾—ã™ã‚‹
            if soup.main:
                return soup.main.get_text()
            elif soup.article:
                return soup.article.get_text()
            else:
                return soup.body.get_text()
    except:
        st.write(traceback.format_exc())  # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’è¡¨ç¤º
        return None

def main():
    init_page()
    chain = init_chain()

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if url := st.text_input("URL: ", key="input"):
        is_valid_url = validate_url(url)
        if not is_valid_url:
            st.write('Please input valid url')
        else:
            if content := get_content(url):
                st.markdown("## Summary")
                st.write_stream(chain.stream({"content": content}))

if __name__ == '__main__':
    main()


