import traceback
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

###### dotenv ã‚’åˆ©ç”¨ã™ã‚‹å ´åˆ ######
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenv not found. Please make sure to set your environment variables manually.", ImportWarning)
################################################


PROMPT = """
1. èª²é¡Œ: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå ±å‘Šã—ãŸæ„Ÿæƒ…ã¨ãã®æ—¥ã®è¨ˆç”»ã«ç›´æ¥é–¢é€£ã™ã‚‹ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ã¾ãŸã¯ãƒªãƒ•ãƒ¬ã‚¯ãƒ†ã‚£ãƒ–ãªå¼•ç”¨ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
1-1. å¼•ç”¨ãŒå…·ä½“çš„ãªæ„Ÿæƒ…çš„æ–‡è„ˆã«åŸºã¥ã„ã¦ã‚µãƒãƒ¼ãƒˆã¾ãŸã¯ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
1-2. ã‚¹ãƒ†ã‚£ãƒ¼ãƒ–ãƒ»ã‚¸ãƒ§ãƒ–ã‚ºã®å¼•ç”¨ã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚
1-3. çŸ¥ã‚‰ã‚Œã–ã‚‹å¼•ç”¨ã‚’æ±‚ã‚ã€å¤šæ§˜ãªæ–‡åŒ–çš„åŠã³æ­´å²çš„æºæ³‰ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ã€é¸æŠã®å¤šæ§˜æ€§ã¨åŒ…æ‹¬æ€§ã‚’è±Šã‹ã«ã—ã¦ãã ã•ã„ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèª¬æ˜ã—ãŸçŠ¶æ³ã«é¸ã‚“ã å¼•ç”¨ãŒã©ã†ãƒ•ã‚£ãƒƒãƒˆã™ã‚‹ã‹ã®ç°¡æ½”ãªèª¬æ˜ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

2. æ„Ÿæƒ…: {feeling}.
3. æ„Ÿæƒ…ã®ç†ç”±: {reason}.
4. ãã®æ—¥ã®è¨ˆç”»: {plan}.
5. æ—¥æœ¬èªã§100èªä»¥å†…ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
"""


def init_page():
    st.set_page_config(
        page_title="ä»Šæ—¥ã®ä¸€è¨€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ",
        page_icon="ğŸ§˜"
    )
    st.header("ä»Šæ—¥ã®ä¸€è¨€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆğŸ§˜")


def select_model(temperature=0):
    models = ("GPT-4o","GPT-4o-mini", "Claude 3.5 Sonnet", "Gemini 1.5 Pro")
    model_choice = st.radio("Choose a model:", models)
    if model_choice == "GPT-4o":
        return ChatOpenAI(temperature=temperature, model_name="gpt-4o")
    elif model_choice == "GPT-4o-mini":
        return ChatOpenAI(temperature=temperature, model_name="gpt-4o-mini")
    elif model_choice == "Claude 3.5 Sonnet":
        return ChatAnthropic(temperature=temperature, model_name="claude-3-5-sonnet-20240620")
    elif model_choice == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(temperature=temperature, model="gemini-1.5-pro-latest")

def init_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_messages([
        ("user", PROMPT),
    ])
    output_parser = StrOutputParser()
    chain = prompt | llm | output_parser
    return chain

       

def main():
    init_page()
    chain = init_chain()
    if chain:
        feeling = st.selectbox(
            "ä»Šæ—¥ã®æ°—åˆ†ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
            ("ã‚‚ã£ã¨ã‚„ã‚‹æ°—ãŒå‡ºã—ãŸã„", "æ‚²ã—ã„æ°—æŒã¡ã§ã™", "æ€’ã£ã¦ã„ã¾ã™", "ä»Šæ—¥ã¯ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ãŸã„", "ãƒ¯ã‚¯ãƒ¯ã‚¯ã—ã¦ã„ã¾ã™", "ä¸å®‰ã§ã™"),
            key="feeling"
        )
        reason = st.text_input("ãã®æ„Ÿæƒ…ã®ç†ç”±ã¯ä½•ã§ã™ã‹ï¼Ÿ", key="reason")
        plan = st.text_input("ä»Šæ—¥ã®äºˆå®šã¯ä½•ã§ã™ã‹ï¼Ÿ", key="plan")
        if st.button("Submit"):
            result = chain.stream({"feeling": feeling, "reason": reason, "plan": plan})
            st.write(result)  


if __name__ == '__main__':
    main()

# Style adjustments (optional, remove if not needed)
st.markdown(
"""
<style>
/* Custom style adjustments */
.st-emotion-cache-iiif1v { display: none !important; }
</style>
""",
    unsafe_allow_html=True,
)


