import traceback
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# dotenvã‚’åˆ©ç”¨ã™ã‚‹å ´åˆ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn("dotenvãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’æ‰‹å‹•ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚", ImportWarning)

PROMPT = """
ã‚ãªãŸã¯ã‚¢ãƒ³ã‚¬ãƒ¼ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã‚’å°‚é–€ã¨ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ€’ã‚Šã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®æ€æ…®æ·±ãã€å®Ÿç”¨çš„ã§åŠ¹æœçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã‚ãªãŸã®ä»•äº‹ã§ã™ï¼š
- æ€’ã£ã¦ã„ã‚‹ç›¸æ‰‹ï¼š{who}
- æ€’ã‚Šã®å…·ä½“çš„ãªåŸå› ï¼š{content}

1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã‚’èªã‚ã¦æ„Ÿæƒ…ã‚’èªè¨¼ã—ã¾ã™ã€‚
2. æ€’ã‚Šã‚’ç®¡ç†ã—ã€è»½æ¸›ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ãªã‚¹ãƒ†ãƒƒãƒ—ã‚„ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚
3. æ ¹æœ¬çš„ãªå•é¡Œã«å»ºè¨­çš„ãªæ–¹æ³•ã§å¯¾å‡¦ã™ã‚‹ã‚ˆã†ã«ä¿ƒã—ã¾ã™ã€‚
4. å°†æ¥åŒæ§˜ã®çŠ¶æ³ã§å½¹ç«‹ã¤è¿½åŠ ã®ãƒªã‚½ãƒ¼ã‚¹ã‚„ãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚
"""

def init_page():
    st.set_page_config(page_title="ã‚¢ãƒ³ã‚¬ãƒ¼ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆğŸ§˜AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒŠãƒ“", page_icon="ğŸ§˜")
    st.header("ã‚¢ãƒ³ã‚¬ãƒ¼ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆğŸ§˜AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒŠãƒ“")

def select_model(temperature=0):
    models = ("GPT-4o", "GPT-4o-mini", "Claude 3.5 Sonnet", "Gemini 1.5 Pro")
    model_choice = st.radio("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ:", models)
    if model_choice == "GPT-4o":
        return ChatOpenAI(temperature=temperature, model_name="gpt-4o")
    elif model_choice == "GPT-4o-mini":
        return ChatOpenAI(temperature=temperature, model_name="gpt-4o-mini")
    elif model_choice == "Claude 3.5 Sonnet":
        return ChatAnthropic(temperature=temperature, model_name="claude-3-5-sonnet-20240620")
    elif model_choice == "Gemini 1.5 Pro":
        return ChatGoogleGenerativeAI(temperature=temperature, model="gemini-1.5-pro-latest")

def init_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_messages([("user", PROMPT)])
    output_parser = StrOutputParser()
    chain = prompt | llm | output_parser
    return chain

def main():
    init_page()
    chain = init_chain()
    if chain:
        who = st.text_input("æ€’ã£ã¦ã„ã‚‹ç›¸æ‰‹ã¯èª°ã§ã™ã‹ï¼Ÿ", key="who")
        content = st.text_area("æ€’ã‚Šã®å…·ä½“çš„ãªåŸå› ã¯ä½•ã§ã™ã‹ï¼Ÿ", key="content")
        if st.button("é€ä¿¡"):
            result = chain.stream({"who": who, "content": content})
            st.write(result)    

if __name__ == '__main__':
    main()

# Style adjustments (optional, remove if not needed)
st.markdown(
"""
<style>
/* Custom style adjustments */
.st-emotion-cache-iiif1v { display: none !important; }
</style>
""",
    unsafe_allow_html=True,
)